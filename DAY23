# day23决策树
1、它是一种监督学习算法，主要用于分类问题，适用于可分类的、连续的输入和输出变量。本质上它是从一层层if/else问题中进行学习并得出结论的。  
2、决策树在逻辑上以树的形式存在，包含根节点、内部节点和叶节点。  
* 根节点：包含数据集中所有数据的集合  
* 内部节点：每个内部节点为一个判断条件，并且包含数据集中满足从根节点到该节点所有条件的数据集合。根据内部结点的判断条件测试结果，内部结点对应数据的集合分别分到两个或者多个子节点中。  
* 叶节点： 叶节点为最终的类别，被包含在该叶节点的数据属于该类别。  
3、决策树学习过程  
* 特征选择：从训练数据的特征中选择一个特征作为当前节点的分裂标准（特征选择的标准不同产生了不同的特征决策树算法）。
* 决策树生成：根据所选特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树停止声场。
* 剪枝：决策树容易过拟合，需要剪枝来缩小树的结构和规模（包括预剪枝和后剪枝）。
4、[决策树算法之ID3](https://blog.csdn.net/acdreamers/article/details/44661149)  
* 信息熵：离散随机事件出现的概率，一个系统越有序其信息熵就越低，反之就越高。   
* 信息增益是针对某个特征而言的，看该系统有无此特征时的信息量各是多少，两者之间的差值就是该特征给系统带来的信息量，即信息增益。  
* 该算法的核心思想就是以信息增益来度量属性的选择，选择分裂后信息增益最大的属性进行分裂。该算法采用自顶向下的贪婪搜索遍历可能的决策空间。
* 
