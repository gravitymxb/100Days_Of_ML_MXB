# 100天机器学习
## day8 逻辑回归  详细概述

* 逻辑回归算法的性质是：它的输出值永远在0-1之间。故适合作为一种分类算法。  
* 分类问题希望使分类器输出值在0-1之间，故需要一个满足该性质的假设函数h(x), 故引出sigmoid函数     具体见[DAY4](https://github.com/gravitymxb/100Days_Of_ML_MXB/blob/master/DAY4.md)   
* 假设函数h(x)的作用是，对于给定的输入变量x，根据选择的参数计算输出变量y=1的可能性。 例如，对于给定的x，通过已确定的参数计算得出h(x)=0.7，则表示有70%的概率y为正向类，相应的有30%的概率y为负向类。  
* 决策边界即预测值分类的分界线。而且它是**假设函数**的一个属性，并非数据集的属性，用数据集只是为了拟合参数，确定了假设函数的参数就确定了决策边界。另外，在假设函数中加入额外的**高阶多项式项**就可以得到更加复杂的决策边界。
* 代价函数的含义是在输出预测值是h(x)，而标签是y的情况下，我们希望学习算法付出的代价。利用梯度下降算法就是为了找到最小的代价函数。
